<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>test on Seb's Blog</title><link>https://sebastienray.github.io/tags/test/</link><description>Recent content in test on Seb's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 03 Dec 2020 12:36:08 +0100</lastBuildDate><atom:link href="https://sebastienray.github.io/tags/test/index.xml" rel="self" type="application/rss+xml"/><item><title>Field testing Niseko website</title><link>https://sebastienray.github.io/posts/eyetracking/</link><pubDate>Thu, 03 Dec 2020 12:36:08 +0100</pubDate><guid>https://sebastienray.github.io/posts/eyetracking/</guid><description>I&amp;rsquo;ve recently discovered a website &amp;ldquo;realeye.io&amp;rdquo; able to do eye tracking using only the webcam. It was during a course named UXLab, and we learned how to do an UX interview using exe tracking and how to analyse the results. That day I went back thinking how I could apply the new knowledge to my activity with Niseko(my agency). Most of our clients are small PME and don&amp;rsquo;t have budgets allowing crazy UX field testing.</description></item></channel></rss>